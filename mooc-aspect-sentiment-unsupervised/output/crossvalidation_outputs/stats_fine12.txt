adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
32  9  2   1  4  7 0  0  0  1  0  1  0  0   0
 6 54  8   8 11  6 0  0  7  0  2  0  3  1   3
 2  9  5   2  0  2 0  0  9  1  1  1  5  0   4
 2 13 15 104 17  6 0  0 89  9  3  3  7 13  18
 0  2  0   1 23  4 0  0  1  1  0  1  0  0   5
 0  6  3  12  6 38 0  0  2  0  0  1  4  0   4
 1  9  6   0  1  3 0  3  8  5  3  1 15  0   1
 0  3  1   1  1  0 0 38  1  5  5 10 13  0   0
 1  6  7  69  7  4 0  2 85 22  6  3  4  8   3
 0  3  3   9  4  0 0  1 16 96 25 14  3  2   3
 2 12 14  10  0  1 0  9 37  7 46 21  3  3   1
 1  0  2   4  1  1 0  1  0  2  1 73  2  0   1
 0  2  2   1  0  2 0  0  0  2  0  2  2  0   2
 1  3 12  16  2  6 0  1 17  1  1  3  0  1   3
 6 16 32  39 20 11 0  2 79 13  1 23  8 38 289
f1 for fientopic 0 0.5765765765765766
precision for fientopic 0 0.5925925925925926
recall for fientopic 0 0.5614035087719298
f1 for fientopic 1 0.421875
precision for fientopic 1 0.3673469387755102
recall for fientopic 1 0.4954128440366973
f1 for fientopic (2) 0.06535947712418301
precision for fientopic (2) 0.044642857142857144
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.3611111111111111
precision for fientopic (3) 0.37545126353790614
recall for fientopic (3) 0.34782608695652173
f1 for finetopic_1 (4) 0.3407407407407408
precision for finetopic_1 (4) 0.23711340206185566
recall for finetopic_1 (4) 0.6052631578947368
f1 for finetopic_1 (5) 0.4550898203592814
precision for finetopic_1 (5) 0.4175824175824176
recall for finetopic_1 (5) 0.5
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5629629629629629
precision for finetopic_1 (7) 0.6666666666666666
recall for finetopic_1 (7) 0.48717948717948717
f1 for finetopic_1 (8) 0.29411764705882354
precision for finetopic_1 (8) 0.24216524216524216
recall for finetopic_1 (8) 0.3744493392070485
f1 for finetopic_1 (9) 0.5581395348837208
precision for finetopic_1 (9) 0.5818181818181818
recall for finetopic_1 (9) 0.5363128491620112
f1 for finetopic_1 (10) 0.3538461538461538
precision for finetopic_1 (10) 0.48936170212765956
recall for finetopic_1 (10) 0.27710843373493976
f1 for finetopic_1 (11) 0.5934959349593496
precision for finetopic_1 (11) 0.46496815286624205
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.04761904761904762
precision for finetopic_1 (12) 0.028985507246376812
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015037593984962405
precision for finetopic_1 (13) 0.015151515151515152
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.6323851203501094
precision for finetopic_1 (14) 0.857566765578635
recall for finetopic_1 (14) 0.5008665511265165
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
32  9  2   1  4  7 0  0  0   1  0  1  0  0   0
 7 54  7  10 11  7 0  0  4   0  2  0  3  1   3
 2  9  5   3  0  2 0  0  8   1  1  1  5  0   4
 2 14 14 121 18  6 0  0 66   9  3  3  7 13  23
 0  2  0   2 23  4 0  0  0   1  0  1  0  0   5
 0  6  3  12  6 40 0  0  1   0  0  1  3  0   4
 1  9  6   0  1  3 0  3  8   5  3  1 15  0   1
 0  3  1   0  1  0 0 39  1   5  5 10 13  0   0
 1  6  8  68  7  4 0  3 83  22  6  4  4  8   3
 0  2  3   8  4  0 0  1 15 100 25 13  3  2   3
 2 11 14   8  0  1 0 10 37   7 50 20  2  3   1
 1  0  2   3  1  1 0  1  0   3  1 73  2  0   1
 0  2  2   1  0  2 0  0  0   2  0  2  2  0   2
 1  3 13  12  3  6 0  2 16   1  2  4  0  1   3
 7 17 30  36 23 11 0  3 24  14  1 23 10 36 342
f1 for fientopic 0 0.5663716814159292
precision for fientopic 0 0.5714285714285714
recall for fientopic 0 0.5614035087719298
f1 for fientopic 1 0.421875
precision for fientopic 1 0.3673469387755102
recall for fientopic 1 0.4954128440366973
f1 for fientopic (2) 0.06622516556291391
precision for fientopic (2) 0.045454545454545456
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.41438356164383566
precision for fientopic (3) 0.4245614035087719
recall for fientopic (3) 0.40468227424749165
f1 for finetopic_1 (4) 0.32857142857142857
precision for finetopic_1 (4) 0.22549019607843138
recall for finetopic_1 (4) 0.6052631578947368
f1 for finetopic_1 (5) 0.4705882352941176
precision for finetopic_1 (5) 0.425531914893617
recall for finetopic_1 (5) 0.5263157894736842
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5571428571428572
precision for finetopic_1 (7) 0.6290322580645161
recall for finetopic_1 (7) 0.5
f1 for finetopic_1 (8) 0.33877551020408164
precision for finetopic_1 (8) 0.3155893536121673
recall for finetopic_1 (8) 0.3656387665198238
f1 for finetopic_1 (9) 0.5714285714285715
precision for finetopic_1 (9) 0.5847953216374269
recall for finetopic_1 (9) 0.5586592178770949
f1 for finetopic_1 (10) 0.3773584905660377
precision for finetopic_1 (10) 0.5050505050505051
recall for finetopic_1 (10) 0.30120481927710846
f1 for finetopic_1 (11) 0.5934959349593496
precision for finetopic_1 (11) 0.46496815286624205
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.04761904761904762
precision for finetopic_1 (12) 0.028985507246376812
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015267175572519083
precision for finetopic_1 (13) 0.015625
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.7037037037037037
precision for finetopic_1 (14) 0.8658227848101265
recall for finetopic_1 (14) 0.5927209705372617
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
32  9  2  0  4  7 0  0   1   1  0  1  0  0   0
 7 54  7  7 11  7 0  0   7   0  2  0  3  1   3
 2  9  5  2  0  2 0  0   9   1  1  1  5  0   4
 2 14 14 44 18  6 0  0 143   9  3  3  7 13  23
 0  2  0  1 23  4 0  0   1   1  0  1  0  0   5
 0  6  3 10  6 40 0  0   3   0  0  1  3  0   4
 1  9  6  0  1  3 0  3   8   5  3  1 15  0   1
 0  3  1  0  1  0 0 39   1   5  5 10 13  0   0
 1  6  8 63  7  4 0  3  88  22  6  4  4  8   3
 0  2  3  7  4  0 0  1  16 100 25 13  3  2   3
 2 11 14  9  0  1 0 10  36   7 50 20  2  3   1
 1  0  2  2  1  1 0  1   1   3  1 73  2  0   1
 0  2  2  1  0  2 0  0   0   2  0  2  2  0   2
 1  3 13 11  3  6 0  2  17   1  2  4  0  1   3
 7 17 30 16 23 11 0  3  44  14  1 23 10 36 342
f1 for fientopic 0 0.5663716814159292
precision for fientopic 0 0.5714285714285714
recall for fientopic 0 0.5614035087719298
f1 for fientopic 1 0.421875
precision for fientopic 1 0.3673469387755102
recall for fientopic 1 0.4954128440366973
f1 for fientopic (2) 0.06622516556291391
precision for fientopic (2) 0.045454545454545456
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.18644067796610173
precision for fientopic (3) 0.2543352601156069
recall for fientopic (3) 0.14715719063545152
f1 for finetopic_1 (4) 0.32857142857142857
precision for finetopic_1 (4) 0.22549019607843138
recall for finetopic_1 (4) 0.6052631578947368
f1 for finetopic_1 (5) 0.4705882352941176
precision for finetopic_1 (5) 0.425531914893617
recall for finetopic_1 (5) 0.5263157894736842
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5571428571428572
precision for finetopic_1 (7) 0.6290322580645161
recall for finetopic_1 (7) 0.5
f1 for finetopic_1 (8) 0.292358803986711
precision for finetopic_1 (8) 0.23466666666666666
recall for finetopic_1 (8) 0.3876651982378855
f1 for finetopic_1 (9) 0.5714285714285715
precision for finetopic_1 (9) 0.5847953216374269
recall for finetopic_1 (9) 0.5586592178770949
f1 for finetopic_1 (10) 0.3773584905660377
precision for finetopic_1 (10) 0.5050505050505051
recall for finetopic_1 (10) 0.30120481927710846
f1 for finetopic_1 (11) 0.5934959349593496
precision for finetopic_1 (11) 0.46496815286624205
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.04761904761904762
precision for finetopic_1 (12) 0.028985507246376812
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015267175572519083
precision for finetopic_1 (13) 0.015625
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.7037037037037037
precision for finetopic_1 (14) 0.8658227848101265
recall for finetopic_1 (14) 0.5927209705372617
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
32  9  2  0  4  7 0  0   1   1  0  1  0  0   0
 7 54  7  6 11  7 0  0   8   0  2  0  3  1   3
 2  9  5  0  0  2 0  0  11   1  1  1  5  0   4
 2 14 14 33 18  6 0  0 154   9  3  3  7 13  23
 0  2  0  1 23  4 0  0   1   1  0  1  0  0   5
 0  6  3  9  6 40 0  0   4   0  0  1  3  0   4
 1  9  6  0  1  3 0  3   8   5  3  1 15  0   1
 0  3  1  0  1  0 0 39   1   5  5 10 13  0   0
 1  6  8 53  7  4 0  3  98  22  6  4  4  8   3
 0  2  3  7  4  0 0  1  16 100 25 13  3  2   3
 2 11 14  5  0  1 0 10  40   7 50 20  2  3   1
 1  0  2  2  1  1 0  1   1   3  1 73  2  0   1
 0  2  2  1  0  2 0  0   0   2  0  2  2  0   2
 1  3 13  7  3  6 0  2  21   1  2  4  0  1   3
 7 17 30 14 23 11 0  3  46  14  1 23 10 36 342
f1 for fientopic 0 0.5663716814159292
precision for fientopic 0 0.5714285714285714
recall for fientopic 0 0.5614035087719298
f1 for fientopic 1 0.421875
precision for fientopic 1 0.3673469387755102
recall for fientopic 1 0.4954128440366973
f1 for fientopic (2) 0.06622516556291391
precision for fientopic (2) 0.045454545454545456
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.15102974828375287
precision for fientopic (3) 0.2391304347826087
recall for fientopic (3) 0.11036789297658862
f1 for finetopic_1 (4) 0.32857142857142857
precision for finetopic_1 (4) 0.22549019607843138
recall for finetopic_1 (4) 0.6052631578947368
f1 for finetopic_1 (5) 0.4705882352941176
precision for finetopic_1 (5) 0.425531914893617
recall for finetopic_1 (5) 0.5263157894736842
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5571428571428572
precision for finetopic_1 (7) 0.6290322580645161
recall for finetopic_1 (7) 0.5
f1 for finetopic_1 (8) 0.30769230769230765
precision for finetopic_1 (8) 0.23902439024390243
recall for finetopic_1 (8) 0.43171806167400884
f1 for finetopic_1 (9) 0.5714285714285715
precision for finetopic_1 (9) 0.5847953216374269
recall for finetopic_1 (9) 0.5586592178770949
f1 for finetopic_1 (10) 0.3773584905660377
precision for finetopic_1 (10) 0.5050505050505051
recall for finetopic_1 (10) 0.30120481927710846
f1 for finetopic_1 (11) 0.5934959349593496
precision for finetopic_1 (11) 0.46496815286624205
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.04761904761904762
precision for finetopic_1 (12) 0.028985507246376812
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015267175572519083
precision for finetopic_1 (13) 0.015625
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.7037037037037037
precision for finetopic_1 (14) 0.8658227848101265
recall for finetopic_1 (14) 0.5927209705372617
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
32  9  2  0  4  7 0  0   1   1  0  1  0  0   0
 7 54  7  6 11  7 0  0   8   0  2  0  3  1   3
 2  9  5  1  0  2 0  0   9   2  1  1  5  0   4
 2 14 14 38 19  9 0  0 148   9  3  3  8 13  19
 0  2  0  1 24  4 0  0   1   1  0  1  0  0   4
 0  6  3 10  6 39 0  0   3   0  0  1  4  0   4
 1  9  7  0  1  3 0  3   7   5  3  1 15  0   1
 0  3  1  0  1  0 0 39   1   5  5 10 13  0   0
 1  6  8 63  8  4 0  3  86  23  6  4  4  8   3
 0  2  3  8  4  0 0  1  15 100 25 13  3  2   3
 2 11 14  9  0  1 0 10  36   7 50 20  2  3   1
 1  0  2  2  1  1 0  1   1   3  1 73  2  0   1
 0  2  2  1  0  2 0  0   0   2  0  2  2  0   2
 1  4 13  8  3  6 0  2  19   1  2  4  0  1   3
 7 17 30 15 23 12 0  3  44  14  1 23 10 36 342
f1 for fientopic 0 0.5663716814159292
precision for fientopic 0 0.5714285714285714
recall for fientopic 0 0.5614035087719298
f1 for fientopic 1 0.4202334630350195
precision for fientopic 1 0.36486486486486486
recall for fientopic 1 0.4954128440366973
f1 for fientopic (2) 0.06578947368421052
precision for fientopic (2) 0.04504504504504504
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.1648590021691974
precision for fientopic (3) 0.2345679012345679
recall for fientopic (3) 0.12709030100334448
f1 for finetopic_1 (4) 0.3356643356643356
precision for finetopic_1 (4) 0.22857142857142856
recall for finetopic_1 (4) 0.631578947368421
f1 for finetopic_1 (5) 0.45086705202312144
precision for finetopic_1 (5) 0.4020618556701031
recall for finetopic_1 (5) 0.5131578947368421
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5571428571428572
precision for finetopic_1 (7) 0.6290322580645161
recall for finetopic_1 (7) 0.5
f1 for finetopic_1 (8) 0.2838283828382838
precision for finetopic_1 (8) 0.22691292875989447
recall for finetopic_1 (8) 0.3788546255506608
f1 for finetopic_1 (9) 0.5681818181818181
precision for finetopic_1 (9) 0.5780346820809249
recall for finetopic_1 (9) 0.5586592178770949
f1 for finetopic_1 (10) 0.3773584905660377
precision for finetopic_1 (10) 0.5050505050505051
recall for finetopic_1 (10) 0.30120481927710846
f1 for finetopic_1 (11) 0.5934959349593496
precision for finetopic_1 (11) 0.46496815286624205
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.046511627906976744
precision for finetopic_1 (12) 0.028169014084507043
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015267175572519083
precision for finetopic_1 (13) 0.015625
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.7073422957600828
precision for finetopic_1 (14) 0.8769230769230769
recall for finetopic_1 (14) 0.5927209705372617
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
31  9  3  0  4  7 0  0   1  1  0  1  0  0   0
 7 55  8  6 11  6 0  0   8  0  2  0  3  0   3
 2  9  5  4  0  2 0  0   6  2  1  1  5  0   4
 2 14 14 34 20  8 0  0 151  9  3  3  8 13  20
 0  2  0  1 24  4 0  0   1  1  0  1  0  0   4
 0  6  3 10  6 39 0  0   3  0  0  1  4  0   4
 1  9  6  2  1  3 0  3   6  5  3  1 15  0   1
 0  3  1  0  1  0 0 39   1  5  5 10 13  0   0
 1  7  8 69  8  4 0  3  80 23  6  4  3  8   3
 0  2  3 11  4  0 0  1  12 99 25 14  3  2   3
 2 12 14 13  0  1 0  9  32  7 50 20  2  3   1
 1  0  2  2  1  1 0  1   1  3  1 73  2  0   1
 0  2  2  1  0  2 0  0   0  2  0  2  2  0   2
 1  4 14 10  3  6 0  1  17  1  2  4  0  1   3
 7 16 31 11 23 12 0  3  48 14  1 24 10 36 341
f1 for fientopic 0 0.5535714285714286
precision for fientopic 0 0.5636363636363636
recall for fientopic 0 0.543859649122807
f1 for fientopic 1 0.4247104247104247
precision for fientopic 1 0.36666666666666664
recall for fientopic 1 0.5045871559633027
f1 for fientopic (2) 0.06451612903225806
precision for fientopic (2) 0.043859649122807015
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.14376321353065538
precision for fientopic (3) 0.19540229885057472
recall for fientopic (3) 0.11371237458193979
f1 for finetopic_1 (4) 0.3333333333333333
precision for finetopic_1 (4) 0.22641509433962265
recall for finetopic_1 (4) 0.631578947368421
f1 for finetopic_1 (5) 0.45614035087719296
precision for finetopic_1 (5) 0.4105263157894737
recall for finetopic_1 (5) 0.5131578947368421
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5652173913043479
precision for finetopic_1 (7) 0.65
recall for finetopic_1 (7) 0.5
f1 for finetopic_1 (8) 0.2693602693602694
precision for finetopic_1 (8) 0.21798365122615804
recall for finetopic_1 (8) 0.3524229074889868
f1 for finetopic_1 (9) 0.5641025641025641
precision for finetopic_1 (9) 0.5755813953488372
recall for finetopic_1 (9) 0.553072625698324
f1 for finetopic_1 (10) 0.3773584905660377
precision for finetopic_1 (10) 0.5050505050505051
recall for finetopic_1 (10) 0.30120481927710846
f1 for finetopic_1 (11) 0.5887096774193549
precision for finetopic_1 (11) 0.4591194968553459
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.047058823529411764
precision for finetopic_1 (12) 0.02857142857142857
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015384615384615384
precision for finetopic_1 (13) 0.015873015873015872
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.7052740434332989
precision for finetopic_1 (14) 0.8743589743589744
recall for finetopic_1 (14) 0.5909878682842288
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
70  18  4   3 17 15 0  1   2   4   0   1  0  0   1
14 127  9   7 18 13 0  0  11   2   2   2  5  0   5
 5  18  7  15  1  6 0  0  18   2   1   3 11  0   8
 3  24 20  78 32 19 0  0 278  16   7   8 16 22  36
 0   2  1   2 42  9 0  0   3   2   0   1  1  0   6
 0  11  5  18 16 77 0  0   9   0   0   4  4  0   5
 1  14 15   7  2  5 0  5  11   6   7   5 17  0   2
 0   5  2   0  1  2 0 76   3   8  10  18 17  0   0
 1  10 14 137 10 11 0  5 157  43  15   8 10 12   6
 0   5  5  25  8  0 0  7  27 187  48  34  5  4   5
 4  22 18  37  3  1 0 11  54  20 110  36  5  6   2
 2   1  3   3  4  1 0  1   7   6   1 158  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1  10 35  26  5  9 0  1  27   1   2   8  1  4   6
 9  39 57  26 41 24 0  6  95  31   5  43 21 87 703
f1 for fientopic 0 0.5691056910569107
precision for fientopic 0 0.6363636363636364
recall for fientopic 0 0.5147058823529411
f1 for fientopic 1 0.48565965583174
precision for fientopic 1 0.41233766233766234
recall for fientopic 1 0.5906976744186047
f1 for fientopic (2) 0.0472972972972973
precision for fientopic (2) 0.03482587064676617
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.16507936507936508
precision for fientopic (3) 0.20207253886010362
recall for fientopic (3) 0.13953488372093023
f1 for finetopic_1 (4) 0.3122676579925651
precision for finetopic_1 (4) 0.21
recall for finetopic_1 (4) 0.6086956521739131
f1 for finetopic_1 (5) 0.4476744186046512
precision for finetopic_1 (5) 0.39487179487179486
recall for finetopic_1 (5) 0.5167785234899329
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5937499999999999
precision for finetopic_1 (7) 0.6666666666666666
recall for finetopic_1 (7) 0.5352112676056338
f1 for finetopic_1 (8) 0.2751971954425942
precision for finetopic_1 (8) 0.22364672364672364
recall for finetopic_1 (8) 0.357630979498861
f1 for finetopic_1 (9) 0.5404624277456648
precision for finetopic_1 (9) 0.5632530120481928
recall for finetopic_1 (9) 0.5194444444444445
f1 for finetopic_1 (10) 0.40892193308550184
precision for finetopic_1 (10) 0.5263157894736842
recall for finetopic_1 (10) 0.3343465045592705
f1 for finetopic_1 (11) 0.5973534971644612
precision for finetopic_1 (11) 0.4716417910447761
recall for finetopic_1 (11) 0.8144329896907216
f1 for finetopic_1 (12) 0.1111111111111111
precision for finetopic_1 (12) 0.072
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.02952029520295203
precision for finetopic_1 (13) 0.02962962962962963
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7104598281960586
precision for finetopic_1 (14) 0.8876262626262627
recall for finetopic_1 (14) 0.5922493681550126
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
71  18  4   3 17 15 0  1   2   3   0   1  0  0   1
15 125  9   7 18 13 0  0  11   2   2   2  5  1   5
 5  18  7  17  1  6 0  0  16   2   1   3 11  0   8
 3  24 20  75 31 20 0  0 281  16   7   8 16 22  36
 0   2  1   3 42  9 0  0   2   2   0   1  1  0   6
 0  11  5  17 15 78 0  0  10   0   0   4  4  0   5
 1  14 15   8  2  5 0  5  10   6   7   5 17  0   2
 0   5  3   0  1  2 0 76   3   8  10  17 17  0   0
 1  11 14 135 10 12 0  5 159  42  15   8  9 12   6
 0   5  5  28  8  0 0  8  24 188  48  33  4  4   5
 4  19 19  36  3  1 0 12  55  20 110  35  7  6   2
 2   1  3   7  4  1 0  1   3   6   1 158  3  0   4
 0   2  6   1  0  3 0  1   1   4   1   6  9  0   3
 1  10 35  23  5  9 0  1  30   1   2   8  1  4   6
 9  38 60  25 40 24 0  5  96  30   5  43 21 88 703
f1 for fientopic 0 0.5725806451612903
precision for fientopic 0 0.6339285714285714
recall for fientopic 0 0.5220588235294118
f1 for fientopic 1 0.4826254826254826
precision for fientopic 1 0.41254125412541254
recall for fientopic 1 0.5813953488372093
f1 for fientopic (2) 0.046511627906976744
precision for fientopic (2) 0.03398058252427184
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.15889830508474576
precision for fientopic (3) 0.19480519480519481
recall for fientopic (3) 0.13416815742397137
f1 for finetopic_1 (4) 0.31578947368421056
precision for finetopic_1 (4) 0.2131979695431472
recall for finetopic_1 (4) 0.6086956521739131
f1 for finetopic_1 (5) 0.4495677233429395
precision for finetopic_1 (5) 0.3939393939393939
recall for finetopic_1 (5) 0.5234899328859061
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5914396887159532
precision for finetopic_1 (7) 0.6608695652173913
recall for finetopic_1 (7) 0.5352112676056338
f1 for finetopic_1 (8) 0.2784588441330998
precision for finetopic_1 (8) 0.22617354196301565
recall for finetopic_1 (8) 0.3621867881548975
f1 for finetopic_1 (9) 0.5449275362318842
precision for finetopic_1 (9) 0.5696969696969697
recall for finetopic_1 (9) 0.5222222222222223
f1 for finetopic_1 (10) 0.40892193308550184
precision for finetopic_1 (10) 0.5263157894736842
recall for finetopic_1 (10) 0.3343465045592705
f1 for finetopic_1 (11) 0.6007604562737643
precision for finetopic_1 (11) 0.4759036144578313
recall for finetopic_1 (11) 0.8144329896907216
f1 for finetopic_1 (12) 0.1111111111111111
precision for finetopic_1 (12) 0.072
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.029304029304029304
precision for finetopic_1 (13) 0.029197080291970802
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7104598281960586
precision for finetopic_1 (14) 0.8876262626262627
recall for finetopic_1 (14) 0.5922493681550126
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
32  9  2  0  4  7 0  0   1   1  0  1  0  0   0
 7 54  7  6 11  7 0  0   8   0  2  0  3  1   3
 2  9  5  0  0  2 0  0  11   1  1  1  5  0   4
 2 14 14 31 18  6 0  0 156   9  3  3  7 13  23
 0  2  0  1 23  4 0  0   1   1  0  1  0  0   5
 0  6  3  9  6 39 0  0   4   0  0  1  4  0   4
 1  9  6  0  1  3 0  3   8   5  3  1 15  0   1
 0  3  1  0  1  0 0 39   1   5  5 10 13  0   0
 1  6  8 53  7  4 0  3  98  22  6  4  4  8   3
 0  2  3  7  4  0 0  1  16 100 25 13  3  2   3
 2 11 14  5  0  1 0 10  40   7 50 20  2  3   1
 1  0  2  2  1  1 0  1   1   3  1 73  2  0   1
 0  2  2  1  0  2 0  0   0   2  0  2  2  0   2
 1  3 13  7  3  6 0  2  21   1  2  4  0  1   3
 7 17 30 14 23 11 0  3  46  14  1 23 10 36 342
f1 for fientopic 0 0.5663716814159292
precision for fientopic 0 0.5714285714285714
recall for fientopic 0 0.5614035087719298
f1 for fientopic 1 0.421875
precision for fientopic 1 0.3673469387755102
recall for fientopic 1 0.4954128440366973
f1 for fientopic (2) 0.06622516556291391
precision for fientopic (2) 0.045454545454545456
recall for fientopic (2) 0.12195121951219512
f1 for fientopic (3) 0.1425287356321839
precision for fientopic (3) 0.22794117647058823
recall for fientopic (3) 0.10367892976588629
f1 for finetopic_1 (4) 0.32857142857142857
precision for finetopic_1 (4) 0.22549019607843138
recall for finetopic_1 (4) 0.6052631578947368
f1 for finetopic_1 (5) 0.4615384615384616
precision for finetopic_1 (5) 0.41935483870967744
recall for finetopic_1 (5) 0.5131578947368421
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5571428571428572
precision for finetopic_1 (7) 0.6290322580645161
recall for finetopic_1 (7) 0.5
f1 for finetopic_1 (8) 0.3067292644757434
precision for finetopic_1 (8) 0.23786407766990292
recall for finetopic_1 (8) 0.43171806167400884
f1 for finetopic_1 (9) 0.5714285714285715
precision for finetopic_1 (9) 0.5847953216374269
recall for finetopic_1 (9) 0.5586592178770949
f1 for finetopic_1 (10) 0.3773584905660377
precision for finetopic_1 (10) 0.5050505050505051
recall for finetopic_1 (10) 0.30120481927710846
f1 for finetopic_1 (11) 0.5934959349593496
precision for finetopic_1 (11) 0.46496815286624205
recall for finetopic_1 (11) 0.8202247191011236
f1 for finetopic_1 (12) 0.047058823529411764
precision for finetopic_1 (12) 0.02857142857142857
recall for finetopic_1 (12) 0.13333333333333333
f1 for finetopic_1 (13) 0.015267175572519083
precision for finetopic_1 (13) 0.015625
recall for finetopic_1 (13) 0.014925373134328358
f1 for finetopic_1 (14) 0.7037037037037037
precision for finetopic_1 (14) 0.8658227848101265
recall for finetopic_1 (14) 0.5927209705372617
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
72  19  4   2 16 14 0  1   3   3   0   1  0  0   1
15 126  8   7 17 15 0  0  11   1   2   2  5  1   5
 5  18  7  18  1  5 0  0  15   2   1   3 12  0   8
 3  24 20  79 32 19 0  0 277  16   7   8 16 22  36
 0   2  1   3 43  9 0  0   2   2   0   1  0  0   6
 0  11  5  18 15 77 0  0   9   0   0   4  5  0   5
 1  13 15   8  2  5 0  5  10   6   7   5 18  0   2
 0   5  2   0  1  2 0 77   3   8  10  17 17  0   0
 1  10 14 130 10 11 0  5 164  43  15   8 10 12   6
 0   5  5  24  8  0 0  8  28 187  48  34  4  4   5
 4  21 18  43  3  1 0 12  48  20 110  36  5  6   2
 2   1  3   6  4  1 0  1   4   6   1 158  3  0   4
 0   2  6   1  0  3 0  1   1   4   1   6  9  0   3
 1  11 34  25  5  9 0  1  28   1   2   8  1  4   6
10  39 57  29 41 24 0  6  92  31   5  43 20 87 703
f1 for fientopic 0 0.576
precision for fientopic 0 0.631578947368421
recall for fientopic 0 0.5294117647058824
f1 for fientopic 1 0.4827586206896552
precision for fientopic 1 0.41042345276872966
recall for fientopic 1 0.586046511627907
f1 for fientopic (2) 0.047619047619047616
precision for fientopic (2) 0.035175879396984924
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.16596638655462184
precision for fientopic (3) 0.2010178117048346
recall for fientopic (3) 0.1413237924865832
f1 for finetopic_1 (4) 0.32209737827715357
precision for finetopic_1 (4) 0.21717171717171718
recall for finetopic_1 (4) 0.6231884057971014
f1 for finetopic_1 (5) 0.4476744186046512
precision for finetopic_1 (5) 0.39487179487179486
recall for finetopic_1 (5) 0.5167785234899329
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5945945945945946
precision for finetopic_1 (7) 0.6581196581196581
recall for finetopic_1 (7) 0.5422535211267606
f1 for finetopic_1 (8) 0.2892416225749559
precision for finetopic_1 (8) 0.23597122302158274
recall for finetopic_1 (8) 0.3735763097949886
f1 for finetopic_1 (9) 0.5420289855072463
precision for finetopic_1 (9) 0.5666666666666667
recall for finetopic_1 (9) 0.5194444444444445
f1 for finetopic_1 (10) 0.40892193308550184
precision for finetopic_1 (10) 0.5263157894736842
recall for finetopic_1 (10) 0.3343465045592705
f1 for finetopic_1 (11) 0.5984848484848485
precision for finetopic_1 (11) 0.47305389221556887
recall for finetopic_1 (11) 0.8144329896907216
f1 for finetopic_1 (12) 0.1111111111111111
precision for finetopic_1 (12) 0.072
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.029411764705882353
precision for finetopic_1 (13) 0.029411764705882353
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7104598281960586
precision for finetopic_1 (14) 0.8876262626262627
recall for finetopic_1 (14) 0.5922493681550126
adding sentimentseeded3 max, alongwith sentiment seeded with slack rulesconfusion matrix15 x 15 matrix
71  19  3   4 17 15 0  1   1   3   0   1  0  0   1
15 127  9   6 17 12 0  0  12   2   2   2  5  1   5
 5  18  7   9  1  5 0  0  25   1   1   3 12  0   8
 3  24 21  61 30 17 0  0 297  15   7   8 15 22  39
 0   2  1   2 43  8 0  0   3   2   0   1  0  0   7
 0  11  5  17 16 77 0  0  10   0   0   4  4  0   5
 1  14 15   7  2  5 0  5  11   6   7   5 17  0   2
 0   5  3   1  1  2 0 76   3   8  10  17 16  0   0
 1  11 14 130  9 10 0  5 170  41  15   8  9 11   5
 0   5  5  25  8  0 0  8  29 185  47  34  5  4   5
 4  20 19  28  3  1 0 11  64  20 109  36  6  6   2
 2   1  3   5  4  1 0  1   5   5   1 159  3  0   4
 0   2  6   1  0  3 0  1   1   4   1   6  9  0   3
 1  10 35  23  5  9 0  0  31   1   2   8  1  4   6
 9  38 59  22 39 23 0  5 101  31   5  42 20 87 706
f1 for fientopic 0 0.5725806451612903
precision for fientopic 0 0.6339285714285714
recall for fientopic 0 0.5220588235294118
f1 for fientopic 1 0.4865900383141762
precision for fientopic 1 0.41368078175895767
recall for fientopic 1 0.5906976744186047
f1 for fientopic (2) 0.04666666666666667
precision for fientopic (2) 0.03414634146341464
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.13555555555555554
precision for fientopic (3) 0.17888563049853373
recall for fientopic (3) 0.10912343470483005
f1 for finetopic_1 (4) 0.3257575757575758
precision for finetopic_1 (4) 0.2205128205128205
recall for finetopic_1 (4) 0.6231884057971014
f1 for finetopic_1 (5) 0.456973293768546
precision for finetopic_1 (5) 0.4095744680851064
recall for finetopic_1 (5) 0.5167785234899329
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.596078431372549
precision for finetopic_1 (7) 0.672566371681416
recall for finetopic_1 (7) 0.5352112676056338
f1 for finetopic_1 (8) 0.2828618968386023
precision for finetopic_1 (8) 0.22280471821756226
recall for finetopic_1 (8) 0.38724373576309795
f1 for finetopic_1 (9) 0.5409356725146197
precision for finetopic_1 (9) 0.5709876543209876
recall for finetopic_1 (9) 0.5138888888888888
f1 for finetopic_1 (10) 0.40671641791044777
precision for finetopic_1 (10) 0.5265700483091788
recall for finetopic_1 (10) 0.331306990881459
f1 for finetopic_1 (11) 0.6022727272727273
precision for finetopic_1 (11) 0.47604790419161674
recall for finetopic_1 (11) 0.8195876288659794
f1 for finetopic_1 (12) 0.11320754716981131
precision for finetopic_1 (12) 0.07377049180327869
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.02952029520295203
precision for finetopic_1 (13) 0.02962962962962963
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7113350125944584
precision for finetopic_1 (14) 0.8847117794486216
recall for finetopic_1 (14) 0.594776748104465
joint sentiment finetopicf1 for fientopic 0.4516786883554458
confusion matrix15 x 15 matrix
72  18  3   3 17 14 0  1   2   4   0   1  0  0   1
15 127  9   7 18 13 0  0  11   1   2   2  5  0   5
 5  18  7  11  1  5 0  0  23   1   1   3 12  0   8
 3  24 21  67 30 17 0  0 291  15   7   8 15 22  39
 0   2  1   2 42  9 0  0   3   2   0   1  0  0   7
 0  11  5  17 15 77 0  0  10   0   0   4  5  0   5
 1  14 15   7  2  5 0  5  11   6   7   5 17  0   2
 0   5  3   1  1  2 0 76   3   8  10  17 16  0   0
 1  11 14 125  9 11 0  5 175  40  15   8  9 11   5
 0   5  5  23  8  0 0  7  31 187  47  34  4  4   5
 4  20 19  34  3  1 0 12  58  20 108  36  6  6   2
 2   1  3   4  4  1 0  1   6   5   1 159  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1  10 34  21  5  9 0  1  33   1   2   8  1  4   6
 9  39 58  22 38 23 0  5 101  31   5  42 21 87 706
f1 for fientopic 0 0.5783132530120482
precision for fientopic 0 0.6371681415929203
recall for fientopic 0 0.5294117647058824
f1 for fientopic 1 0.4865900383141762
precision for fientopic 1 0.41368078175895767
recall for fientopic 1 0.5906976744186047
f1 for fientopic (2) 0.046979865771812075
precision for fientopic (2) 0.034482758620689655
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.14806629834254142
precision for fientopic (3) 0.1936416184971098
recall for fientopic (3) 0.11985688729874776
f1 for finetopic_1 (4) 0.3206106870229008
precision for finetopic_1 (4) 0.21761658031088082
recall for finetopic_1 (4) 0.6086956521739131
f1 for finetopic_1 (5) 0.45427728613569324
precision for finetopic_1 (5) 0.4052631578947368
recall for finetopic_1 (5) 0.5167785234899329
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5937499999999999
precision for finetopic_1 (7) 0.6666666666666666
recall for finetopic_1 (7) 0.5352112676056338
f1 for finetopic_1 (8) 0.29239766081871343
precision for finetopic_1 (8) 0.23087071240105542
recall for finetopic_1 (8) 0.39863325740318906
f1 for finetopic_1 (9) 0.5459854014598541
precision for finetopic_1 (9) 0.5753846153846154
recall for finetopic_1 (9) 0.5194444444444445
f1 for finetopic_1 (10) 0.40373831775700936
precision for finetopic_1 (10) 0.5242718446601942
recall for finetopic_1 (10) 0.3282674772036474
f1 for finetopic_1 (11) 0.6022727272727273
precision for finetopic_1 (11) 0.47604790419161674
recall for finetopic_1 (11) 0.8195876288659794
f1 for finetopic_1 (12) 0.11249999999999999
precision for finetopic_1 (12) 0.07317073170731707
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.02962962962962963
precision for finetopic_1 (13) 0.029850746268656716
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7113350125944584
precision for finetopic_1 (14) 0.8847117794486216
recall for finetopic_1 (14) 0.594776748104465
joint sentiment finetopicf1 for fientopic 0.45888413197518957
confusion matrix15 x 15 matrix
73  19  3   4 16 14 0  1   1   3   0   1  0  0   1
14 126  8  11 18 14 0  0   7   2   2   2  5  1   5
 5  18  7  11  1  5 0  0  23   1   1   3 12  0   8
 3  24 21 127 30 18 0  0 230  15   7   8 15 22  39
 0   2  1   3 41  9 0  0   2   2   0   1  1  0   7
 0  11  5  17 16 77 0  0  10   0   0   4  4  0   5
 1  14 15  10  2  5 0  5   8   6   7   5 17  0   2
 0   5  3   2  1  2 0 76   2   8  10  17 16  0   0
 1  11 14 170  9 11 0  5 130  40  15   8  9 11   5
 0   5  5  32  8  0 0  8  22 185  47  35  4  4   5
 4  22 18  42  3  1 0 11  50  20 108  35  7  6   2
 2   1  3   4  4  1 0  1   6   5   1 159  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1   9 35  29  5  9 0  1  25   1   2   8  1  4   6
10  39 59  33 39 23 0  5  90  31   5  42 20 85 706
f1 for fientopic 0 0.5840000000000001
precision for fientopic 0 0.6403508771929824
recall for fientopic 0 0.5367647058823529
f1 for fientopic 1 0.4818355640535373
precision for fientopic 1 0.4090909090909091
recall for fientopic 1 0.586046511627907
f1 for fientopic (2) 0.046979865771812075
precision for fientopic (2) 0.034482758620689655
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.24053030303030304
precision for fientopic (3) 0.25553319919517103
recall for fientopic (3) 0.22719141323792486
f1 for finetopic_1 (4) 0.31297709923664124
precision for finetopic_1 (4) 0.21243523316062177
recall for finetopic_1 (4) 0.5942028985507246
f1 for finetopic_1 (5) 0.4516129032258065
precision for finetopic_1 (5) 0.4010416666666667
recall for finetopic_1 (5) 0.5167785234899329
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5937499999999999
precision for finetopic_1 (7) 0.6666666666666666
recall for finetopic_1 (7) 0.5352112676056338
f1 for finetopic_1 (8) 0.24880382775119617
precision for finetopic_1 (8) 0.2145214521452145
recall for finetopic_1 (8) 0.296127562642369
f1 for finetopic_1 (9) 0.541727672035139
precision for finetopic_1 (9) 0.5727554179566563
recall for finetopic_1 (9) 0.5138888888888888
f1 for finetopic_1 (10) 0.40373831775700936
precision for finetopic_1 (10) 0.5242718446601942
recall for finetopic_1 (10) 0.3282674772036474
f1 for finetopic_1 (11) 0.6022727272727273
precision for finetopic_1 (11) 0.47604790419161674
recall for finetopic_1 (11) 0.8195876288659794
f1 for finetopic_1 (12) 0.11249999999999999
precision for finetopic_1 (12) 0.07317073170731707
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.02973977695167286
precision for finetopic_1 (13) 0.03007518796992481
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7113350125944584
precision for finetopic_1 (14) 0.8847117794486216
recall for finetopic_1 (14) 0.594776748104465
joint sentiment finetopicf1 for fientopic 0.47180721107823764
confusion matrix15 x 15 matrix
72  18  3   5 16 15 0  1   0   4   0   1  0  0   1
15 126  9  12 18 13 0  0   6   2   2   2  5  0   5
 5  18  8  13  1  5 0  0  21   1   1   3 12  0   7
 3  24 21 170 30 19 0  0 189  15   7   8 15 22  36
 0   2  1   2 41  9 0  0   3   2   0   1  1  0   7
 0  11  5  17 16 76 0  0  10   0   0   4  5  0   5
 1  14 15   5  2  5 0  5  13   6   7   5 17  0   2
 0   5  3   1  1  2 0 75   3   8  10  18 16  0   0
 1  10 14 155  9 11 0  5 145  40  15   8 10 11   5
 0   5  5  32  8  0 0  7  22 188  47  33  4  4   5
 4  22 18  39  3  1 0 11  53  20 108  35  7  6   2
 2   1  3   8  4  1 0  1   2   6   1 158  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1  10 33  29  5  9 0  2  25   1   2   8  1  4   6
10  39 58  48 40 23 0  6  77  31   5  42 21 85 702
f1 for fientopic 0 0.576
precision for fientopic 0 0.631578947368421
recall for fientopic 0 0.5294117647058824
f1 for fientopic 1 0.4827586206896552
precision for fientopic 1 0.41042345276872966
recall for fientopic 1 0.586046511627907
f1 for fientopic (2) 0.05387205387205388
precision for fientopic (2) 0.039603960396039604
recall for fientopic (2) 0.08421052631578947
f1 for fientopic (3) 0.3099361896080219
precision for fientopic (3) 0.3159851301115242
recall for fientopic (3) 0.3041144901610018
f1 for finetopic_1 (4) 0.31178707224334595
precision for finetopic_1 (4) 0.211340206185567
recall for finetopic_1 (4) 0.5942028985507246
f1 for finetopic_1 (5) 0.4457478005865102
precision for finetopic_1 (5) 0.3958333333333333
recall for finetopic_1 (5) 0.5100671140939598
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.5859375
precision for finetopic_1 (7) 0.6578947368421053
recall for finetopic_1 (7) 0.528169014084507
f1 for finetopic_1 (8) 0.2876984126984127
precision for finetopic_1 (8) 0.2548330404217926
recall for finetopic_1 (8) 0.33029612756264237
f1 for finetopic_1 (9) 0.5465116279069768
precision for finetopic_1 (9) 0.573170731707317
recall for finetopic_1 (9) 0.5222222222222223
f1 for finetopic_1 (10) 0.40373831775700936
precision for finetopic_1 (10) 0.5242718446601942
recall for finetopic_1 (10) 0.3282674772036474
f1 for finetopic_1 (11) 0.6007604562737643
precision for finetopic_1 (11) 0.4759036144578313
recall for finetopic_1 (11) 0.8144329896907216
f1 for finetopic_1 (12) 0.11042944785276072
precision for finetopic_1 (12) 0.07142857142857142
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.02985074626865672
precision for finetopic_1 (13) 0.030303030303030304
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7101669195751138
precision for finetopic_1 (14) 0.8886075949367088
recall for finetopic_1 (14) 0.5914069081718618
joint sentiment finetopicf1 for fientopic 0.47341283683138846
confusion matrix15 x 15 matrix
72  18  3   5 16 15 0  1   0   4   0   1  0  0   1
15 128  9  10 17 13 0  0   8   1   2   2  5  0   5
 5  18  8  15  1  5 0  0  19   1   1   3 12  0   7
 3  24 21 171 31 18 0  0 188  15   7   8 15 22  36
 0   2  1   2 43  8 0  0   3   2   0   1  0  0   7
 0  11  5  18 16 76 0  0   9   0   0   4  5  0   5
 1  14 15   9  2  5 0  5   9   6   7   5 17  0   2
 0   5  2   1  1  2 0 76   3   8  10  18 16  0   0
 1  10 14 155  9 11 0  5 145  40  15   8 10 11   5
 0   5  5  31  8  0 0  7  23 187  47  33  5  4   5
 4  20 18  38  3  1 0 12  54  20 109  36  6  6   2
 2   1  3   7  4  1 0  1   3   6   1 158  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1   9 35  34  5  9 0  1  20   1   2   8  1  4   6
10  40 58  44 39 23 0  4  81  30   5  42 21 87 703
f1 for fientopic 0 0.576
precision for fientopic 0 0.631578947368421
recall for fientopic 0 0.5294117647058824
f1 for fientopic 1 0.49042145593869735
precision for fientopic 1 0.4169381107491857
recall for fientopic 1 0.5953488372093023
f1 for fientopic (2) 0.05369127516778524
precision for fientopic (2) 0.03940886699507389
recall for fientopic (2) 0.08421052631578947
f1 for fientopic (3) 0.31062670299727524
precision for fientopic (3) 0.3154981549815498
recall for fientopic (3) 0.30590339892665475
f1 for finetopic_1 (4) 0.3257575757575758
precision for finetopic_1 (4) 0.2205128205128205
recall for finetopic_1 (4) 0.6231884057971014
f1 for finetopic_1 (5) 0.44837758112094395
precision for finetopic_1 (5) 0.4
recall for finetopic_1 (5) 0.5100671140939598
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.596078431372549
precision for finetopic_1 (7) 0.672566371681416
recall for finetopic_1 (7) 0.5352112676056338
f1 for finetopic_1 (8) 0.28884462151394424
precision for finetopic_1 (8) 0.25663716814159293
recall for finetopic_1 (8) 0.33029612756264237
f1 for finetopic_1 (9) 0.5459854014598541
precision for finetopic_1 (9) 0.5753846153846154
recall for finetopic_1 (9) 0.5194444444444445
f1 for finetopic_1 (10) 0.40671641791044777
precision for finetopic_1 (10) 0.5265700483091788
recall for finetopic_1 (10) 0.331306990881459
f1 for finetopic_1 (11) 0.5996204933586338
precision for finetopic_1 (11) 0.4744744744744745
recall for finetopic_1 (11) 0.8144329896907216
f1 for finetopic_1 (12) 0.1111111111111111
precision for finetopic_1 (12) 0.072
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.02962962962962963
precision for finetopic_1 (13) 0.029850746268656716
recall for finetopic_1 (13) 0.029411764705882353
f1 for finetopic_1 (14) 0.7108190091001011
precision for finetopic_1 (14) 0.888748419721871
recall for finetopic_1 (14) 0.5922493681550126
joint sentiment finetopicf1 for fientopic 0.4941474443528398
confusion matrix15 x 15 matrix
71  18  3   4 17 15 0  1   1   4   0   1  0  0   1
15 128  8  10 18 13 0  0   8   2   2   2  4  0   5
 5  18  7   7  1  6 0  0  27   1   1   3 11  0   8
 3  24 22 228 31 18 0  0 133  15   8   7 12 21  37
 0   2  1   4 43  8 0  0   1   2   0   1  0  0   7
 0  11  5  21 15 79 0  0   6   0   0   4  3  0   5
 1  14 15   7  2  5 0  5  12   6   7   4 17  0   2
 0   5  2   1  1  2 0 80   3  10  12  14 11  0   1
 1  11 15 131 10 11 0  5 172  41  15   4  7 11   5
 0   7  5  27  8  0 0  7  27 191  47  29  2  4   6
 4  20 21  25  3  1 0 12  67  20 113  30  5  6   2
 2   1  3   8  4  1 0  1   3   7   2 155  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1  10 35  28  5  9 0  1  27   1   3   7  1  2   6
10  41 60  73 41 23 0  5  54  31   7  39 18 80 705
f1 for fientopic 0 0.570281124497992
precision for fientopic 0 0.6283185840707964
recall for fientopic 0 0.5220588235294118
f1 for fientopic 1 0.4857685009487666
precision for fientopic 1 0.41025641025641024
recall for fientopic 1 0.5953488372093023
f1 for fientopic (2) 0.0462046204620462
precision for fientopic (2) 0.03365384615384615
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.401762114537445
precision for fientopic (3) 0.3958333333333333
recall for fientopic (3) 0.407871198568873
f1 for finetopic_1 (4) 0.3208955223880597
precision for finetopic_1 (4) 0.21608040201005024
recall for finetopic_1 (4) 0.6231884057971014
f1 for finetopic_1 (5) 0.4606413994169096
precision for finetopic_1 (5) 0.4072164948453608
recall for finetopic_1 (5) 0.5302013422818792
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.6153846153846153
precision for finetopic_1 (7) 0.6779661016949152
recall for finetopic_1 (7) 0.5633802816901409
f1 for finetopic_1 (8) 0.3510204081632653
precision for finetopic_1 (8) 0.3179297597042514
recall for finetopic_1 (8) 0.3917995444191344
f1 for finetopic_1 (9) 0.5496402877697842
precision for finetopic_1 (9) 0.5701492537313433
recall for finetopic_1 (9) 0.5305555555555556
f1 for finetopic_1 (10) 0.4131627056672761
precision for finetopic_1 (10) 0.518348623853211
recall for finetopic_1 (10) 0.3434650455927052
f1 for finetopic_1 (11) 0.62
precision for finetopic_1 (11) 0.5065359477124183
recall for finetopic_1 (11) 0.7989690721649485
f1 for finetopic_1 (12) 0.1285714285714286
precision for finetopic_1 (12) 0.08737864077669903
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.015384615384615384
precision for finetopic_1 (13) 0.016129032258064516
recall for finetopic_1 (13) 0.014705882352941176
f1 for finetopic_1 (14) 0.7106854838709679
precision for finetopic_1 (14) 0.8845671267252195
recall for finetopic_1 (14) 0.5939342881213142
joint sentiment finetopicf1 for fientopic 0.4626975499434812
confusion matrix15 x 15 matrix
71  45  2   3 10  4 0  0   0   0   0   1  0  0   0
18 127  6  11 21  9 0  0   5   1   2   6  7  0   2
 2  19  9  11  0  5 0  1  24   4   2   3  9  0   6
 0  27 23 188 20 21 0  0 140  26   7  14 47 22  24
 0   1  0   4 38 11 0  0   2   4   0   1  7  0   1
 1   9  5  23 11 70 0  0   3   2   0   0  5  0  20
 0  11  8   7  0  1 0  4  14   8   8   4 32  0   0
 0   4  2   1  1  5 0 79   3  11  10  12 13  0   1
 0  12 16 152  4 17 0  6 147  39  17   6  7 13   3
 1   6 10  29  3  7 0  9  22 185  46  33  4  5   0
 8  17 24  44  2  0 0 10  50  31 106  27  3  6   1
 0   3  0   4  0  4 0  1   1  16   2 158  2  0   3
 0   2  7   1  1  3 0  1   0   8   0   4  9  0   1
 0  10 35  27  3  7 0  0  22   4   3   9  3  1  12
51  36 64  82 22 32 0  3  31  63   3  46 13 80 661
f1 for fientopic 0 0.4930555555555556
precision for fientopic 0 0.46710526315789475
recall for fientopic 0 0.5220588235294118
f1 for fientopic 1 0.46691176470588236
precision for fientopic 1 0.3860182370820669
recall for fientopic 1 0.5906976744186047
f1 for fientopic (2) 0.058823529411764705
precision for fientopic (2) 0.04265402843601896
recall for fientopic (2) 0.09473684210526316
f1 for fientopic (3) 0.3280977312390925
precision for fientopic (3) 0.3202725724020443
recall for fientopic (3) 0.3363148479427549
f1 for finetopic_1 (4) 0.37073170731707317
precision for finetopic_1 (4) 0.27941176470588236
recall for finetopic_1 (4) 0.5507246376811594
f1 for finetopic_1 (5) 0.40579710144927533
precision for finetopic_1 (5) 0.35714285714285715
recall for finetopic_1 (5) 0.4697986577181208
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.6171875
precision for finetopic_1 (7) 0.6929824561403509
recall for finetopic_1 (7) 0.5563380281690141
f1 for finetopic_1 (8) 0.32558139534883723
precision for finetopic_1 (8) 0.3168103448275862
recall for finetopic_1 (8) 0.3348519362186788
f1 for finetopic_1 (9) 0.48556430446194226
precision for finetopic_1 (9) 0.4601990049751244
recall for finetopic_1 (9) 0.5138888888888888
f1 for finetopic_1 (10) 0.39626168224299063
precision for finetopic_1 (10) 0.5145631067961165
recall for finetopic_1 (10) 0.3221884498480243
f1 for finetopic_1 (11) 0.61003861003861
precision for finetopic_1 (11) 0.4876543209876543
recall for finetopic_1 (11) 0.8144329896907216
f1 for finetopic_1 (12) 0.09090909090909093
precision for finetopic_1 (12) 0.055900621118012424
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.0076045627376425855
precision for finetopic_1 (13) 0.007874015748031496
recall for finetopic_1 (13) 0.007352941176470588
f1 for finetopic_1 (14) 0.687825182101977
precision for finetopic_1 (14) 0.8993197278911564
recall for finetopic_1 (14) 0.556866048862679
joint sentiment finetopicf1 for fientopic 0.4967236763155978
confusion matrix15 x 15 matrix
73  19  3   4 16 14 0  1   1   3   0   1  0  0   1
15 127  9   8 18 13 0  0  10   2   2   2  4  0   5
 5  18  7   6  1  6 0  0  28   1   1   3 11  0   8
 3  24 22 228 30 19 0  0 133  15   8   7 12 21  37
 0   2  1   4 43  8 0  0   1   2   0   1  0  0   7
 0  11  5  22 15 79 0  0   5   0   0   4  3  0   5
 1  14 15   5  2  5 0  5  14   6   7   4 17  0   2
 0   5  2   1  1  2 0 80   3  10  12  14 11  0   1
 1  11 15 122 10 11 0  5 181  41  15   4  7 11   5
 0   6  5  27  8  0 0  8  27 191  47  29  2  4   6
 4  20 19  22  3  1 0 13  70  20 114  30  5  6   2
 2   1  3   8  4  1 0  1   3   7   2 155  3  0   4
 0   2  6   2  0  3 0  1   0   4   1   6  9  0   3
 1  10 36  27  5  9 0  0  28   1   3   7  1  2   6
10  39 61  75 41 23 0  6  52  31   7  39 18 80 705
f1 for fientopic 0 0.5816733067729084
precision for fientopic 0 0.6347826086956522
recall for fientopic 0 0.5367647058823529
f1 for fientopic 1 0.4847328244274809
precision for fientopic 1 0.4110032362459547
recall for fientopic 1 0.5906976744186047
f1 for fientopic (2) 0.046052631578947366
precision for fientopic (2) 0.03349282296650718
recall for fientopic (2) 0.07368421052631578
f1 for fientopic (3) 0.40714285714285714
precision for fientopic (3) 0.40641711229946526
recall for fientopic (3) 0.407871198568873
f1 for finetopic_1 (4) 0.3233082706766917
precision for finetopic_1 (4) 0.2182741116751269
recall for finetopic_1 (4) 0.6231884057971014
f1 for finetopic_1 (5) 0.4606413994169096
precision for finetopic_1 (5) 0.4072164948453608
recall for finetopic_1 (5) 0.5302013422818792
f1 for finetopic_1 (6) 0.0
precision for finetopic_1 (6) 1.0
recall for finetopic_1 (6) 0.0
f1 for finetopic_1 (7) 0.6106870229007634
precision for finetopic_1 (7) 0.6666666666666666
recall for finetopic_1 (7) 0.5633802816901409
f1 for finetopic_1 (8) 0.36381909547738694
precision for finetopic_1 (8) 0.3255395683453237
recall for finetopic_1 (8) 0.4123006833712984
f1 for finetopic_1 (9) 0.5504322766570605
precision for finetopic_1 (9) 0.5718562874251497
recall for finetopic_1 (9) 0.5305555555555556
f1 for finetopic_1 (10) 0.4160583941605839
precision for finetopic_1 (10) 0.5205479452054794
recall for finetopic_1 (10) 0.3465045592705167
f1 for finetopic_1 (11) 0.62
precision for finetopic_1 (11) 0.5065359477124183
recall for finetopic_1 (11) 0.7989690721649485
f1 for finetopic_1 (12) 0.1285714285714286
precision for finetopic_1 (12) 0.08737864077669903
recall for finetopic_1 (12) 0.24324324324324326
f1 for finetopic_1 (13) 0.015384615384615384
precision for finetopic_1 (13) 0.016129032258064516
recall for finetopic_1 (13) 0.014705882352941176
f1 for finetopic_1 (14) 0.7106854838709679
precision for finetopic_1 (14) 0.8845671267252195
recall for finetopic_1 (14) 0.5939342881213142
